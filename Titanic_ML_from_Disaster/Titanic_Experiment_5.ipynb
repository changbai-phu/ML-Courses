{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: \n",
    "- compare the original ensemble approach (similar to bagging ensemble, but with alternatives in creating multiple GBT models by changing seeds instead of boosting the same models iteratively) with ensemble using Stacking technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/content/train.csv\")\n",
    "serving_df = pd.read_csv(\"/content/test.csv\")\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    def normalize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "\n",
    "    def ticket_number(x):\n",
    "        return x.split(\" \")[-1]\n",
    "\n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "\n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "    return df\n",
    "\n",
    "preprocessed_train_df = preprocess(train_df)\n",
    "preprocessed_serving_df = preprocess(serving_df)\n",
    "\n",
    "preprocessed_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_features = list(preprocessed_train_df.columns)\n",
    "input_features.remove(\"Ticket\")\n",
    "input_features.remove(\"PassengerId\")\n",
    "input_features.remove(\"Survived\")\n",
    "#input_features.remove(\"Ticket_number\")\n",
    "\n",
    "print(f\"Input features: {input_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# split train set to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "train_df, valid_df = train_test_split(preprocessed_train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "def tokenize_names(features, labels=None):\n",
    "    \"\"\"Divite the names into tokens. TF-DF can consume text tokens natively.\"\"\"\n",
    "    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n",
    "    return features, labels\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"Survived\").map(tokenize_names)\n",
    "valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df, label=\"Survived\").map(tokenize_names)\n",
    "serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "predictions = None\n",
    "num_predictions = 0\n",
    "\n",
    "for i in range(100):\n",
    "    print(f\"i:{i}\")\n",
    "    # Possible models: GradientBoostedTreesModel or RandomForestModel\n",
    "    model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        verbose=0, # Very few logs\n",
    "        features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
    "        exclude_non_specified_features=True, # Only use the features in \"features\"\n",
    "\n",
    "        #min_examples=1,\n",
    "        #categorical_algorithm=\"RANDOM\",\n",
    "        ##max_depth=4,\n",
    "        #shrinkage=0.05,\n",
    "        ##num_candidate_attributes_ratio=0.2,\n",
    "        #split_axis=\"SPARSE_OBLIQUE\",\n",
    "        #sparse_oblique_normalization=\"MIN_MAX\",\n",
    "        #sparse_oblique_num_projections_exponent=2.0,\n",
    "        #num_trees=2000,\n",
    "        ##validation_ratio=0.0,\n",
    "        random_seed=i,\n",
    "        honest=True,\n",
    "    )\n",
    "    model.fit(train_ds, validation_data=valid_ds)\n",
    "    \n",
    "    sub_predictions = model.predict(valid_ds, verbose=0)[:,0]\n",
    "    if predictions is None:\n",
    "        predictions = sub_predictions\n",
    "    else:\n",
    "        predictions += sub_predictions\n",
    "    num_predictions += 1\n",
    "\n",
    "predictions/=num_predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert averaged predictions to final class labels (for classification)\n",
    "final_predictions = (predictions > 0.5).astype(int)  # For binary classification\n",
    "\n",
    "# Extract true labels from valid_ds\n",
    "y_valid = np.concatenate([y.numpy() for x, y in valid_ds])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_valid, final_predictions)\n",
    "\n",
    "# Calculate log loss (requires probability predictions)\n",
    "loss = log_loss(y_valid, predictions)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Ensemble Log Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Ensemble Accuracy: 0.8101\n",
    "Ensemble Log Loss: 0.4051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for x, y in valid_ds])\n",
    "y_prob = predictions\n",
    "y_pred = (y_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Survived\", \"Survived\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Ensemble Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Plot Classification Metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "values = [accuracy, precision, recall, f1]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.title(\"Classification Metrics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Print metrics for reference\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")  # Diagonal line (random classifier)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Number of models in the bagging ensemble\n",
    "num_models = 10\n",
    "\n",
    "# Store predictions from each model\n",
    "bagging_predictions = []\n",
    "random_seeds = [int(seed) for seed in np.random.randint(0, 10000, num_models)] # Different seeds for bootstrapping\n",
    "\n",
    "for i, seed in enumerate(random_seeds):\n",
    "    print(f\"Training model {i+1}/{num_models} with seed {seed}\")\n",
    "\n",
    "    # Create a new model with different data sampling\n",
    "    model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        random_seed=random_seeds[i], \n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Train the model on the training dataset\n",
    "    model.fit(train_ds, validation_data=valid_ds)\n",
    "\n",
    "    # Predict on the validation dataset\n",
    "    sub_predictions = model.predict(valid_ds, verbose=0)[:, 0]  # Get probability scores\n",
    "    bagging_predictions.append(sub_predictions)\n",
    "\n",
    "# Convert list to NumPy array for averaging\n",
    "bagging_predictions = np.array(bagging_predictions)\n",
    "y_prob = np.mean(bagging_predictions, axis=0)  # Average over models\n",
    "\n",
    "# Convert probabilities to class predictions (threshold at 0.5 for binary classification)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Extract true labels from valid_ds\n",
    "y_true = np.concatenate([y.numpy() for x, y in valid_ds])\n",
    "\n",
    "# Compute accuracy and log loss\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "logloss = log_loss(y_true, y_prob)\n",
    "\n",
    "print(f\"Bagging Ensemble Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Bagging Ensemble Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Bagging Ensemble Accuracy: 0.8156\n",
    "Bagging Ensemble Log Loss: 0.4183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking with logistic regression as meta model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Number of base models in the stacking ensemble\n",
    "num_models = 5  \n",
    "\n",
    "# Generate random seeds for model variation\n",
    "random_seeds = [int(seed) for seed in np.random.randint(0, 10000, num_models)]  \n",
    "\n",
    "# Store base model predictions\n",
    "base_model_predictions = []\n",
    "\n",
    "for i, seed in enumerate(random_seeds):\n",
    "    print(f\"Training base model {i+1}/{num_models} with seed {seed}\")\n",
    "\n",
    "    # Train a base model with different random seeds\n",
    "    model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        random_seed=seed, \n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Train the model on training dataset\n",
    "    model.fit(train_ds, validation_data=valid_ds)\n",
    "\n",
    "    # Predict on the validation dataset (probabilities)\n",
    "    sub_predictions = model.predict(valid_ds, verbose=0)[:, 0]  # Get probability scores\n",
    "    base_model_predictions.append(sub_predictions)\n",
    "\n",
    "# Convert to NumPy array (shape: [num_models, num_samples])\n",
    "base_model_predictions = np.array(base_model_predictions).T  # Transpose to shape (num_samples, num_models)\n",
    "\n",
    "# Extract true labels from valid_ds\n",
    "y_true = np.concatenate([y.numpy() for x, y in valid_ds])\n",
    "\n",
    "# Train a meta-model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(base_model_predictions, y_true)\n",
    "\n",
    "# Make final predictions using the meta-model\n",
    "y_prob = meta_model.predict_proba(base_model_predictions)[:, 1]  # Probability of class 1\n",
    "y_pred = (y_prob > 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "# Compute accuracy and log loss\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "logloss = log_loss(y_true, y_prob)\n",
    "\n",
    "print(f\"Stacking Ensemble Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Stacking Ensemble Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Stacking Ensemble Accuracy: 0.8268\n",
    "Stacking Ensemble Log Loss: 0.4156"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
