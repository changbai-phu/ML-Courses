{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search vs Grid Search\n",
    "- Conclusion from the experiment result: random search has better performance (higher accuracy 0.8741 than grid search 0.8357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Original Random Search\n",
    "tuner = tfdf.tuner.RandomSearch(num_trials=1000)\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n",
    "\n",
    "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
    "\n",
    "#tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "\n",
    "\n",
    "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
    "oblique_space.choice(\"sparse_oblique_normalization\",\n",
    "                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n",
    "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n",
    "\n",
    "# Tune the model. Notice the `tuner=tuner`.\n",
    "tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "tuned_model.fit(train_ds, verbose=0, validation_data=valid_ds)\n",
    "\n",
    "tuned_self_evaluation = tuned_model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss:{tuned_self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.8741258978843689 \n",
    "Loss:0.7747772932052612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "y_true = valid_df['Survived'].values\n",
    "y_pred = tuned_model.predict(valid_ds)\n",
    "y_pred = y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get probability predictions for ROC Curve\n",
    "y_prob = tuned_model.predict(valid_ds).flatten()\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "class TFDFWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, min_examples=2, categorical_algorithm=\"CART\", max_depth=6, shrinkage=0.1):\n",
    "        self.min_examples = min_examples\n",
    "        self.categorical_algorithm = categorical_algorithm\n",
    "        self.max_depth = max_depth\n",
    "        self.shrinkage = shrinkage\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        train_df = X.copy()\n",
    "        train_df['Survived'] = y\n",
    "        \n",
    "        train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"Survived\").map(tokenize_names)\n",
    "        \n",
    "        self.model = tfdf.keras.GradientBoostedTreesModel(\n",
    "            min_examples=self.min_examples,\n",
    "            categorical_algorithm=self.categorical_algorithm,\n",
    "            max_depth=self.max_depth,\n",
    "            shrinkage=self.shrinkage\n",
    "        )\n",
    "        self.model.fit(train_ds, verbose=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        ds = tfdf.keras.pd_dataframe_to_tf_dataset(X).map(tokenize_names)\n",
    "        predictions = self.model.predict(ds)\n",
    "        return predictions.round().flatten()  # Ensure it's flattened for compatibility\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "# Split the dataset\n",
    "train_df, valid_df = train_test_split(preprocessed_train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_df[input_features]\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'min_examples': [2, 5, 7, 10],\n",
    "    'categorical_algorithm': [\"CART\", \"RANDOM\"],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'shrinkage': [0.02, 0.05, 0.10, 0.15]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=TFDFWrapper(), param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Best parameters: {'categorical_algorithm': 'RANDOM', 'max_depth': 3, 'min_examples': 7, 'shrinkage': 0.02}\n",
    "Best accuracy: 0.8357030575943457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ground truth values from validation set\n",
    "y_true = valid_df['Survived'].values\n",
    "\n",
    "# Predict using the best estimator from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(valid_df[input_features])\n",
    "\n",
    "# Round the predictions\n",
    "y_pred = y_pred.round()\n",
    "\n",
    "# Check predictions\n",
    "print(f\"True values: {y_true[:10]}\")\n",
    "print(f\"Predictions: {y_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = best_model.predict(valid_df[input_features]).flatten()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
