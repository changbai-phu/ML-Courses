{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First encounter a new dataset:\n",
    "1. construct a ranking with a feature utility metric (\"**mutual information**\") - a function measuring associations between a feature and the target.\n",
    "    - mutual information: can detect any kind of relationship, while correlation only detects linear relationship. \n",
    "    - high MI: a feature contains significant information about the target\n",
    "    - low MI: a feature does not provide much useful information about the target\n",
    "        - feature interactions: MI evaluates each feature individually w.r.t. the target, some features may become useful when combine with other features. So low MI doen't necessary mean useless. \n",
    "        - domain knowledge\n",
    "        - correlation: check if low MI feature is correlated with other highly informative features.\n",
    "2. Choose a smaller set of the most useful features to develop first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual Information\n",
    "- a meaure of uncertainty between two quantities. \n",
    "- if knew the value of a feature, how much more confident would you be about the target?\n",
    "- \"entropy\": how many yes-or-no questions you would need to describe an occurance of that variable on average.\n",
    "- when MI = 0, the quantities are independent. \n",
    "- MI > 2.0 are uncommon since MI is a logarithmic quantity.\n",
    "- MI is a univariate metric, can't detect interactions between features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - 1985 Automobiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "df = pd.read_csv(\"../input/fe-course-data/autos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"price\")\n",
    "\n",
    "# Label encoding for categoricals\n",
    "for colname in X.select_dtypes(\"object\"):\n",
    "    X[colname], _ = X[colname].factorize()\n",
    "\n",
    "# All discrete features should now have integer dtypes (double-check this before using MI!)\n",
    "discrete_features = X.dtypes == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "mi_scores[::3]  # show a few features with their MI scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curb_weight          1.540126\n",
    "highway_mpg          0.951700\n",
    "length               0.621566\n",
    "fuel_system          0.485085\n",
    "stroke               0.389321\n",
    "num_of_cylinders     0.330988\n",
    "compression_ratio    0.133927\n",
    "fuel_type            0.048139\n",
    "Name: MI Scores, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.relplot(x=\"curb_weight\", y=\"price\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deciding a feature is unimportant from its MI score, it's good to investigate any possible interaction effects -- domain knowledge can offer a lot of guidance here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"horsepower\", y=\"price\", hue=\"fuel_type\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.feature_engineering_new.ex2 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../input/fe-course-data/ames.csv\")\n",
    "\n",
    "\n",
    "# Utility functions from Tutorial\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "features = [\"YearBuilt\", \"MoSold\", \"ScreenPorch\"]\n",
    "sns.relplot(\n",
    "    x=\"value\", y=\"SalePrice\", col=\"variable\", data=df.melt(id_vars=\"SalePrice\", value_vars=features), facet_kws=dict(sharex=False),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understand mutual information\n",
    "Based on the plots, which feature do you think would have the highest mutual information with SalePrice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own Ans: YearBuilt - because can see a clear pattern between SalePrice and YearBuilt. <br>\n",
    "<br>\n",
    "Correct Ans: Based on the plots, YearBuilt should have the highest MI score since knowing the year tends to constrain SalePrice to a smaller range of possible values. This is generally not the case for MoSold, however. Finally, since ScreenPorch is usually just one value, 0, on average it won't tell you much about SalePrice (though more than MoSold) .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# compute mutual information scores for the Ames features:\n",
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "mi_scores = make_mi_scores(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(mi_scores.head(20))\n",
    "print(mi_scores.tail(20))  # uncomment to see bottom 20\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores.head(20))\n",
    "plot_mi_scores(mi_scores.tail(20))  # uncomment to see bottom 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverallQual     0.581262\n",
    "Neighborhood    0.569813\n",
    "GrLivArea       0.496909\n",
    "YearBuilt       0.437939\n",
    "GarageArea      0.415014\n",
    "TotalBsmtSF     0.390280\n",
    "GarageCars      0.381467\n",
    "FirstFlrSF      0.368825\n",
    "BsmtQual        0.364779\n",
    "KitchenQual     0.326194\n",
    "ExterQual       0.322390\n",
    "YearRemodAdd    0.315402\n",
    "MSSubClass      0.287131\n",
    "GarageFinish    0.265440\n",
    "FullBath        0.251693\n",
    "Foundation      0.236115\n",
    "LotFrontage     0.233334\n",
    "GarageType      0.226117\n",
    "FireplaceQu     0.221955\n",
    "SecondFlrSF     0.200658\n",
    "Name: MI Scores, dtype: float64\n",
    "ExterCond           0.020934\n",
    "KitchenAbvGr        0.017677\n",
    "BsmtHalfBath        0.013719\n",
    "LotConfig           0.013637\n",
    "ScreenPorch         0.012981\n",
    "PoolArea            0.012831\n",
    "MiscVal             0.010997\n",
    "LowQualFinSF        0.009328\n",
    "Heating             0.007622\n",
    "Functional          0.006380\n",
    "MiscFeature         0.004322\n",
    "Street              0.003381\n",
    "Condition2          0.003176\n",
    "RoofMatl            0.002620\n",
    "PoolQC              0.001370\n",
    "Utilities           0.000291\n",
    "Threeseasonporch    0.000000\n",
    "BsmtFinSF2          0.000000\n",
    "MoSold              0.000000\n",
    "LandSlope           0.000000\n",
    "Name: MI Scores, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine MI \n",
    "Do the scores seem reasonable? Do the high scoring features represent things you'd think most people would value in a home? Do you notice any themes in what they describe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own Ans: The scores seem reasonable.  \n",
    "<br>\n",
    "Correct Ans: Some common themes among most of these features are:<br>\n",
    "Location: Neighborhood<br>\n",
    "Size: all of the Area and SF features, and counts like FullBath and GarageCars <br>\n",
    "Quality: all of the Qual features<br>\n",
    "Year: YearBuilt and YearRemodAdd<br>\n",
    "Types: descriptions of features and styles like Foundation and GarageType<br>\n",
    "These are all the kinds of features you'll commonly see in real-estate listings (like on Zillow), It's good then that our mutual information metric scored them highly. On the other hand, the lowest ranked features seem to mostly represent things that are rare or exceptional in some way, and so wouldn't be relevant to the average home buyer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# investigate possible interaction effects for the BldgType feature\n",
    "sns.catplot(x=\"BldgType\", y=\"SalePrice\", data=df, kind=\"boxen\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate whether BldgType produces a significant interaction with either of the following: <br>\n",
    "<br>\n",
    "GrLivArea  # Above ground living area <br>\n",
    "MoSold     # Month sold <br>\n",
    "Run the following cell twice, the first time with feature = \"GrLivArea\" and the next time with feature=\"MoSold\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# feature = \"GrLivArea\"\n",
    "feature=\"MoSold\"\n",
    "\n",
    "sns.lmplot(\n",
    "    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n",
    "    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The trend lines being significantly different from one category to the next indicates an interaction effect.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Discover Interactions\n",
    "From the plots, does BldgType seem to exhibit an interaction effect with either GrLivArea or MoSold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own Ans: yes.\n",
    "\n",
    "<br>\n",
    "Correct Ans: The trends lines within each category of BldgType are clearly very different, indicating an interaction between these features. Since knowing BldgType tells us more about how GrLivArea relates to SalePrice, we should consider including BldgType in our feature set. <br>\n",
    "The trend lines for MoSold, however, are almost all the same. This feature hasn't become more informative for knowing BldgType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mi_scores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverallQual     0.581262\n",
    "Neighborhood    0.569813\n",
    "GrLivArea       0.496909\n",
    "YearBuilt       0.437939\n",
    "GarageArea      0.415014\n",
    "TotalBsmtSF     0.390280\n",
    "GarageCars      0.381467\n",
    "FirstFlrSF      0.368825\n",
    "BsmtQual        0.364779\n",
    "KitchenQual     0.326194\n",
    "Name: MI Scores, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "themes: Location, size, and quality. <br>\n",
    "One strategy: Combining these top features with other related features, especially those you've identified as creating interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
