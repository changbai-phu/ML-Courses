{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common transformations in Pandas:\n",
    "1. Mathematical transforms: apply mathematical operaations to columns \n",
    "    - e.g., Box-Cox Transformation - normalizer \n",
    "2. Counts\n",
    "    - aggregate binary/boolean features\n",
    "    - e.g., count how many values are greater than 0 for each row \n",
    "3. Building-up and Breaking-down features\n",
    "    - split strings to multiple features to extract useful information or join features into a composed feature\n",
    "4. Group transforms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips on discovering new features\n",
    "1. Understand the features. Refer to your dataset's data documentation.\n",
    "2. Research the problem domain to acquire domain knowledge. \n",
    "3. Study previous work - solution write-ups from past Kaggle competitions.\n",
    "4. Use data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "accidents = pd.read_csv(\"../input/fe-course-data/accidents.csv\")\n",
    "autos = pd.read_csv(\"../input/fe-course-data/autos.csv\")\n",
    "concrete = pd.read_csv(\"../input/fe-course-data/concrete.csv\")\n",
    "customer = pd.read_csv(\"../input/fe-course-data/customer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mathematical transforms\n",
    "- apply arithmetic operations to columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "autos[\"stroke_ratio\"] = autos.stroke / autos.bore\n",
    "\n",
    "autos[[\"stroke\", \"bore\", \"stroke_ratio\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# measure of power\n",
    "autos[\"displacement\"] = (\n",
    "    np.pi * ((0.5 * autos.bore) ** 2) * autos.stroke * autos.num_of_cylinders\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization can help to suggest transformations.\n",
    "e.g., the distribution of WindSpeed is highly skewed. Thus, logarithm is effective to normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If the feature has 0.0 values, use np.log1p (log(1+x)) instead of np.log\n",
    "accidents[\"LogWindSpeed\"] = accidents.WindSpeed.apply(np.log1p)\n",
    "\n",
    "# Plot a comparison\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.kdeplot(accidents.WindSpeed, shade=True, ax=axs[0])\n",
    "sns.kdeplot(accidents.LogWindSpeed, shade=True, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Counts\n",
    "- aggregate binary or boolean features (presence or absence) to create a count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "roadway_features = [\"Amenity\", \"Bump\", \"Crossing\", \"GiveWay\",\n",
    "    \"Junction\", \"NoExit\", \"Railway\", \"Roundabout\", \"Station\", \"Stop\",\n",
    "    \"TrafficCalming\", \"TrafficSignal\"]\n",
    "accidents[\"RoadwayFeatures\"] = accidents[roadway_features].sum(axis=1)\n",
    "\n",
    "accidents[roadway_features + [\"RoadwayFeatures\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# .gt() is a shorthand for “greater than”\n",
    "# check how many values are greater than 0 for each row \n",
    "\n",
    "components = [ \"Cement\", \"BlastFurnaceSlag\", \"FlyAsh\", \"Water\",\n",
    "               \"Superplasticizer\", \"CoarseAggregate\", \"FineAggregate\"]\n",
    "concrete[\"Components\"] = concrete[components].gt(0).sum(axis=1)\n",
    "\n",
    "concrete[components + [\"Components\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building-up and Breaking-down features\n",
    "- for entries that have complex strings (e.g., phone number (999)-444-1234, street address, URL, dates etc)\n",
    "- The str accessor lets you apply string methods like split directly to columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "customer[[\"Type\", \"Level\"]] = (  # Create two new features\n",
    "    customer[\"Policy\"]           # from the Policy feature\n",
    "    .str                         # through the string accessor\n",
    "    .split(\" \", expand=True)     # by splitting on \" \"\n",
    "                                 # and expanding the result into separate columns\n",
    ")\n",
    "\n",
    "customer[[\"Policy\", \"Type\", \"Level\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\tPolicy\tType\tLevel\n",
    "0\tCorporate L3\tCorporate\tL3\n",
    "1\tPersonal L3\tPersonal\tL3\n",
    "2\tPersonal L3\tPersonal\tL3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- join simple features into a composed feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "autos[\"make_and_style\"] = autos[\"make\"] + \"_\" + autos[\"body_style\"]\n",
    "autos[[\"make\", \"body_style\", \"make_and_style\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Group transforms \n",
    "- aggregate information across multiple rows grouped by some category\n",
    "- Using an aggregation function tp combine two features: a categorical feature that provides the grouping and another feature whose values you wish to aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# average income by state\n",
    "\n",
    "customer[\"AverageIncome\"] = (\n",
    "    customer.groupby(\"State\")  # for each state\n",
    "    [\"Income\"]                 # select the income\n",
    "    .transform(\"mean\")         # and compute its mean\n",
    ")\n",
    "\n",
    "customer[[\"State\", \"Income\", \"AverageIncome\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the frequency with which each state occurs in the dataset:\n",
    "\n",
    "customer[\"StateFreq\"] = (\n",
    "    customer.groupby(\"State\")\n",
    "    [\"State\"]\n",
    "    .transform(\"count\")\n",
    "    / customer.State.count()\n",
    ")\n",
    "\n",
    "customer[[\"State\", \"StateFreq\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a grouped feature using only the training set and then join it to the validation set.\n",
    "    -  can use the validation set's merge method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create splits\n",
    "df_train = customer.sample(frac=0.5)\n",
    "df_valid = customer.drop(df_train.index)\n",
    "\n",
    "# Create the average claim amount by coverage type, on the training set\n",
    "df_train[\"AverageClaim\"] = df_train.groupby(\"Coverage\")[\"ClaimAmount\"].transform(\"mean\")\n",
    "\n",
    "# Merge the values into the validation set\n",
    "df_valid = df_valid.merge(\n",
    "    df_train[[\"Coverage\", \"AverageClaim\"]].drop_duplicates(),\n",
    "    on=\"Coverage\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_valid[[\"Coverage\", \"AverageClaim\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips on Creating Features\n",
    "It's good to keep in mind your model's own strengths and weaknesses when creating features. Here are some guidelines: <br>\n",
    "- Linear models learn sums and differences naturally, but can't learn anything more complex.\n",
    "- Ratios seem to be difficult for most models to learn. Ratio combinations often lead to some easy performance gains.\n",
    "- Linear models and neural nets generally do better with normalized features. Neural nets especially need features scaled to values not too far from 0. \n",
    "- Tree-based models (like random forests and XGBoost) can sometimes benefit from normalization, but usually much less so.\n",
    "Tree models can learn to approximate almost any combination of features, but when a combination is especially important they can still benefit from having it explicitly created, especially when data is limited. \n",
    "- Counts are especially helpful for tree models, since these models don't have a natural way of aggregating information across many features at once.\n",
    "- (Above fully copied from Kaggle Online Course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.feature_engineering_new.ex3 import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    score = cross_val_score(\n",
    "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "df = pd.read_csv(\"../input/fe-course-data/ames.csv\")\n",
    "X = df.copy()\n",
    "y = X.pop(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create mathematical transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_1[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n",
    "X_1[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n",
    "X_1[\"TotalOutsideSF\"] = df.WoodDeckSF + df.OpenPorchSF + df.EnclosedPorch + df.Threeseasonporch + df.ScreenPorch\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've discovered an interaction effect between a numeric feature and a categorical feature, you might want to model it explicitly using a one-hot encoding, like so:\n",
    "\n",
    "# One-hot encode Categorical feature, adding a column prefix \"Cat\"\n",
    "X_new = pd.get_dummies(df.Categorical, prefix=\"Cat\")\n",
    "\n",
    "# Multiply row-by-row\n",
    "X_new = X_new.mul(df.Continuous, axis=0)\n",
    "\n",
    "# Join the new features to the feature set\n",
    "X = X.join(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Interaction with a categorical \n",
    "- We discovered an interaction between BldgType and GrLivArea in Exercise 2. Now create their interaction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot encode BldgType. Use `prefix=\"Bldg\"` in `get_dummies`\n",
    "X_2 = pd.get_dummies(df.BldgType, prefix='Bldg')\n",
    "# Multiply\n",
    "X_2 = X_2.mul(df.GrLivArea, axis=0)\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count Feature\n",
    "- Let's try creating a feature that describes how many kinds of outdoor areas a dwelling has. Create a feature PorchTypes that counts how many of the following are greater than 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_3 = pd.DataFrame()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "types = [\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
    "\"Threeseasonporch\",\"ScreenPorch\"]\n",
    "X_3[\"PorchTypes\"] = df[types].gt(0).sum(axis=1)\n",
    "\n",
    "# Check your answer\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Break down a categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# describe the type of a dwelling\n",
    "df.MSSubClass.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array(['One_Story_1946_and_Newer_All_Styles', 'Two_Story_1946_and_Newer',\n",
    "       'One_Story_PUD_1946_and_Newer',\n",
    "       'One_and_Half_Story_Finished_All_Ages', 'Split_Foyer',\n",
    "       'Two_Story_PUD_1946_and_Newer', 'Split_or_Multilevel',\n",
    "       'One_Story_1945_and_Older', 'Duplex_All_Styles_and_Ages',\n",
    "       'Two_Family_conversion_All_Styles_and_Ages',\n",
    "       'One_and_Half_Story_Unfinished_All_Ages',\n",
    "       'Two_Story_1945_and_Older', 'Two_and_Half_Story_All_Ages',\n",
    "       'One_Story_with_Finished_Attic_All_Ages',\n",
    "       'PUD_Multilevel_Split_Level_Foyer',\n",
    "       'One_and_Half_Story_PUD_All_Ages'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there is a more general categorization described (roughly) by the first word of each category. Create a feature containing only these first words by splitting MSSubClass at the first underscore _. (Hint: In the split method use an argument n=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_4 = pd.DataFrame()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X_4['MSClass'] = (\n",
    "    df[\"MSSubClass\"]\n",
    "    .str\n",
    "    .split(\"_\", n=1, expand=True))[0]\n",
    "\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use a grouped transform\n",
    "- The value of a home often depends on how it compares to typical homes in its neighborhood. Create a feature MedNhbdArea that describes the median of GrLivArea grouped on Neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_5 = pd.DataFrame()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X_5[\"MedNhbdArea\"] = (\n",
    "    df.groupby(\"Neighborhood\")\n",
    "    [\"GrLivArea\"]\n",
    "    .transform(\"median\")\n",
    ")\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've made your first new feature set! If you like, you can run the cell below to score the model with all of your new features added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_new = X.join([X_1, X_2, X_3, X_4, X_5])\n",
    "score_dataset(X_new, y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
