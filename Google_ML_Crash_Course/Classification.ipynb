{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfication\n",
    "- to predict which categories an example belongs to. \n",
    "- convert a logistic regression model to a binary classification model to predict one of two classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholds and the confusion matrix\n",
    "- **Thresholds**: logistic will give values between 0~1, which is the probability of (for instance) an email is spam or not. We need a threshold value to determine that above what probability, the email is spam. And below what probability, the email is not spam. This is threshold.\n",
    "    - While, considering a corner but also important case, what if the predicted probability equals to the threshold? \n",
    "        - it actually depends on how the tools/platforms/library implement the threshold.\n",
    "            - keras treats the value equals to threshold as negative, which is not spam.\n",
    "    - threshold has to be considered carefully, especially the cost of wrong prediction.\n",
    "        - e.g., face recognition key: cost of recognizing a stranger as a family member and let he/she unlock the key vs cost of recognizing a family member as a stranger.\n",
    "    - threshold also has to deal with **imbalanced dataset**\n",
    "        - e.g., face recognition dataset: maybe 5 out of 50 is family member, and the others are delivery people/technicians/etc\n",
    "- **confusion matrix**: use to track true postive, false positive, false negative and true negative. Actual positive and negative as two columns, predicted positive and negative as two rows. \n",
    "    - true positive: both actual and predicted are positive\n",
    "    - true negative: both actual and predicted are negative\n",
    "    - false positive: actual negative, but predicted positive\n",
    "    - false negative: actual positive, but predicted negative\n",
    "- in general, when the classification threshold increases, both true and false positives decrease, both true and false negtives increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, recall, precision, and related metrics\n",
    "\n",
    "Metric\tGuidance\n",
    "Accuracy\t\n",
    "Use as a rough indicator of model training progress/convergence for balanced datasets.\n",
    "\n",
    "For model performance, use only in combination with other metrics.\n",
    "\n",
    "Avoid for imbalanced datasets. Consider using another metric.\n",
    "\n",
    "Recall\n",
    "(True positive rate)\tUse when false negatives are more expensive than false positives.\n",
    "False positive rate\tUse when false positives are more expensive than false negatives.\n",
    "Precision\tUse when it's very important for positive predictions to be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Guidance|\n",
    "|---|---|\n",
    "|Accuracy|- Use as a rough indicator of model training progress/convergence for balanced datasets.  - For model performance, use only in combination with other metrics. - Avoid for imbalanced datasets. Consider using another metric. |\n",
    "|Recall (True positive rate)|Use when false negatives are more expensive than false positives.|\n",
    "|False positive rate|Use when false positives are more expensive than false negatives.|\n",
    "|Precision|Use when it's very important for positive predictions to be accurate.|"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
