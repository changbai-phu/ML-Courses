{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "- relationship between features and labels\n",
    "- equation: $y =  b + w_1x_1$, y is the predicted values (output), b is bias (y-intecept and sometimes refer as $w_0$), $w_1$ is weight (slope m), and $x_1$ is the features (input).\n",
    "    - bias and weight are calculated/updated during training.\n",
    "\n",
    "Loss:\n",
    "- the difference between the predicted values and actual values, don't care about the direction -> taking absolute value of the difference or square of the difference.\n",
    "- mainly 4 types of loss:\n",
    "    - $L_1$ loss: $\\sum|actual\\,value - predicted\\,value|$\n",
    "    - MAE (mean absolute error): $\\frac{1}{N}\\sum|actual\\,value - predicted\\,value|$\n",
    "    - $L_2$ loss: $\\sum(actual\\,value - predicted\\,value)^2$\n",
    "    - MSE (mean squared error): $\\frac{1}{N}\\sum(actual\\,value - predicted\\,value)^2$\n",
    "- MSE and MAE are preferred for multiple features\n",
    "- choose proper loss function:\n",
    "    - MSE/$L_2$ loss if want to fit tighly to data, including outliers because squaring will amplify differences (large error, loss larger) and causing high penalty and so the model tends to move heavily toward the outlier.\n",
    "    - MAE/$L_1$ loss if want to avoid outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
