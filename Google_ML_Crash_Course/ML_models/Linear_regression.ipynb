{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "- relationship between features and labels\n",
    "- equation: $y =  b + w_1x_1$, y is the predicted values (output), b is bias (y-intecept and sometimes refer as $w_0$), $w_1$ is weight (slope m), and $x_1$ is the features (input).\n",
    "    - bias and weight are calculated/updated during training.\n",
    "\n",
    "Loss:\n",
    "- the difference between the predicted values and actual values, don't care about the direction -> taking absolute value of the difference or square of the difference.\n",
    "- mainly 4 types of loss:\n",
    "    - $L_1$ loss: $\\sum|actual\\,value - predicted\\,value|$\n",
    "    - MAE (mean absolute error): $\\frac{1}{N}\\sum|actual\\,value - predicted\\,value|$\n",
    "    - $L_2$ loss: $\\sum(actual\\,value - predicted\\,value)^2$\n",
    "    - MSE (mean squared error): $\\frac{1}{N}\\sum(actual\\,value - predicted\\,value)^2$\n",
    "- MSE and MAE are preferred for multiple features\n",
    "- choose proper loss function:\n",
    "    - MSE/$L_2$ loss if want to fit tighly to data, including outliers because squaring will amplify differences (large error, loss larger) and causing high penalty and so the model tends to move heavily toward the outlier.\n",
    "    - MAE/$L_1$ loss if want to avoid outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent:\n",
    "- an iterative method that is used to find the optimal values for parameters (weights and bias) that produce the lowest loss.\n",
    "- steps:\n",
    "    1. Set weight = 0, bias = 0\n",
    "    2. Calculate loss using current paramters\n",
    "    3. Determine the direction to move the weights and bias that reduce loss\n",
    "        - direction: calculate the slope of the tangent to the loss function at each weight and bias = the derivative of the loss function w.r.t the weight and the bias.\n",
    "    4. Move the weight and bias values a small amount (which is gradient multiply by the learning rate) in the direction determined above\n",
    "    5. Repeat step 2 and so on, until the model **converges**.\n",
    "- When graph the loss surface for a model with one feature, it is a **convex** shape (weight and bias have a slop ~ 0).\n",
    "    - A linear model converges when it's found the minimum loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters: \n",
    "- control different aspect of training\n",
    "- 3 common hyperparameters:\n",
    "    - Learning rate: how quickly the model converges\n",
    "        - small -> converge slowly, too many iterations\n",
    "        - large -> never converge, fluctuate\n",
    "    - Batch size: number of examples the model processes before updating weights and bias\n",
    "        - **Stochastic gradient descent (SGD)**\n",
    "            - use only a single example (batch size = 1) per iteration\n",
    "            - produce noise: varations during training cause the loss to increase during iteration \n",
    "        - **Mini-batch stochastic gradient descent**\n",
    "            - 1 < batch size < N \n",
    "            - soze choosed at random, take average of gradients, and update weights and bias once per iteration\n",
    "        - larger batch sizes can help reduce the negative effects of having outliers in the data\n",
    "    - Epochs\n",
    "        - means the model has processed every example in the training set once\n",
    "        - e.g., 1000 examples with mini-batch size = 100, it will take 10 iterations to complete one epoch\n",
    "        - more epoch, better model, more time to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Code - Load dependencies\n",
    "\n",
    "#general\n",
    "import io\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "import keras\n",
    "\n",
    "# data visualization\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chicago_taxi_dataset = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/chicago_taxi_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Code - Read dataset\n",
    "\n",
    "# Updates dataframe to use specific columns.\n",
    "training_df = chicago_taxi_dataset[['TRIP_MILES', 'TRIP_SECONDS', 'FARE', 'COMPANY', 'PAYMENT_TYPE', 'TIP_RATE']]\n",
    "\n",
    "print('Read dataset completed successfully.')\n",
    "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
    "training_df.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P2: Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Code - View dataset statistics\n",
    "\n",
    "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
    "training_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Total number of rows: 31694\n",
    "\n",
    "TRIP_MILES\tTRIP_SECONDS\tFARE\tCOMPANY\tPAYMENT_TYPE\tTIP_RATE\n",
    "count\t31694.000000\t31694.000000\t31694.000000\t31694\t31694\t31694.000000\n",
    "unique\tNaN\tNaN\tNaN\t31\t7\tNaN\n",
    "top\tNaN\tNaN\tNaN\tFlash Cab\tCredit Card\tNaN\n",
    "freq\tNaN\tNaN\tNaN\t7887\t14142\tNaN\n",
    "mean\t8.289463\t1319.796397\t23.905210\tNaN\tNaN\t12.965785\n",
    "std\t7.265672\t928.932873\t16.970022\tNaN\tNaN\t15.517765\n",
    "min\t0.500000\t60.000000\t3.250000\tNaN\tNaN\t0.000000\n",
    "25%\t1.720000\t548.000000\t9.000000\tNaN\tNaN\t0.000000\n",
    "50%\t5.920000\t1081.000000\t18.750000\tNaN\tNaN\t12.200000\n",
    "75%\t14.500000\t1888.000000\t38.750000\tNaN\tNaN\t20.800000\n",
    "max\t68.120000\t7140.000000\t159.250000\tNaN\tNaN\t648.600000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the maximum fare?\n",
    "- 159.250000\n",
    "What is the mean distance across all trips?\n",
    "- 8.289463 miles\n",
    "How many cab companies are in the dataset?\n",
    "- 31\n",
    "What is the most frequent payment type?\n",
    "- Credit Card\n",
    "Are any features missing data?\n",
    "- No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN: if the result of a calculation can not be computed or if there is missing information. For example, numeric information required for categorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate a correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
